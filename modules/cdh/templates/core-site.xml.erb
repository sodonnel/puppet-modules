<?xml version="1.0"?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

  <% if @secure %>
  <property>
    <name>hadoop.security.authentication</name>
    <value>kerberos</value>
  </property>
  <% end %>
  
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://<%= @namenodehostname -%>:8020</value>
  </property>

  <!-- Time before trash is deleted in minutes. Recommend 1440 (1 day) -->
  <property>
    <name>fs.trash.interval</name>
    <value>60</value>
  </property>

  <!-- Time before trashcheckpoints are created in minutes -->
  <property>
    <name>fs.trash.checkpoint.interval</name>
    <value>30</value>
  </property>

  <!-- How much data is buffered during read and write operations.
       Default is 4K. Recommend 64K -->
  <property>
    <name>io.file.buffer.size</name>
    <value>65536</value>
  </property>

  
  <property>
    <name>hadoop.proxyuser.mapred.groups</name>
    <value>*</value>
  </property>

  <property>
    <name>hadoop.proxyuser.mapred.hosts</name>
    <value>*</value>
  </property>

  <!-- Required to enable hive impersonation -->
  <property>
    <name>hadoop.proxyuser.hive.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.hive.groups</name>
    <value>*</value>
  </property>

  <!-- Require for oozie -->
  <property>
      <name>hadoop.proxyuser.oozie.hosts</name>
      <value>*</value>
    </property>
    
    <property>
      <name>hadoop.proxyuser.oozie.groups</name>
      <value>*</value>
    </property>

  <!-- Require for hue -->
  <property>
    <name>hadoop.proxyuser.hue.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.hue.groups</name>
    <value>*</value>
  </property>

  <% if @encryption %>

    <property>
      <name>hadoop.ssl.require.client.cert</name>
      <value>false</value>
      <final>true</final>
    </property>

    <property>
      <name>hadoop.ssl.hostname.verifier</name>
      <value>DEFAULT</value>
      <final>true</final>
    </property>

    <property>
      <name>hadoop.ssl.keystores.factory.class</name>
      <value>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory</value>
      <final>true</final>
    </property>

    <property>
      <name>hadoop.ssl.server.conf</name>
      <value>ssl-server.xml</value>
      <final>true</final>
    </property>

    <property>
      <name>hadoop.ssl.client.conf</name>
      <value>ssl-client.xml</value>
      <final>true</final>
    </property>

    <property>
      <name>hadoop.ssl.enabled</name>
      <value>true</value>
    </property>

    <property>
      <name>hadoop.rpc.protection</name>
      <value>privacy</value>
    </property>
    
    <% end %>

    <!-- Basic settings for KMS running locally

On CDH 5.14.0, for some reason I cannot get to the bottom if, kms-server just exits after about 30
seconds and no errors are present in any log files I can find.

However if I run the command from the command line it stays up and works fine.

For some reason I have not figured out, this only works on non-secure (no Kerberos).


To get it working uncomment the TWO parameters below and then:

yum install hadoop-kms hadoop-kms-server

Then edit /etc/hadoop-kms/conf/kms-site.xml and comment out the property:

hadoop.security.keystore.java-keystore-provider.password-file

Then run the following as root:

sudo -u kms /usr/java/jdk1.8.0_152/bin/java -Djava.util.logging.config.file=/var/lib/hadoop-kms/tomcat-deployment/conf/logging.properties -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager -Djdk.tls.ephemeralDHKeySize=2048 -Dproc_kms -Dkms.log.dir=/var/log/hadoop-kms/ -Djava.library.path=/usr/lib/hadoop/libexec/../lib/native/ -Djava.endorsed.dirs=/usr/lib/bigtop-tomcat/endorsed -classpath /usr/lib/bigtop-tomcat/bin/bootstrap.jar -Dcatalina.base=/var/lib/hadoop-kms/tomcat-deployment -Dcatalina.home=/usr/lib/bigtop-tomcat -Djava.io.tmpdir=/var/run/hadoop-kms org.apache.catalina.startup.Bootstrap kms start

  -->  
  <!-- <property>
    <name>hadoop.security.key.provider.path</name>
    <value>kms://http@localhost:16000/kms</value>
  </property> 

  <property>
    <name>dfs.encryption.key.provider.uri</name>
    <value>kms://http@localhost:16000/kms</value>
  </property>

  -->
    
</configuration>
